---

- name: configure hadoop core-site.xml
  copy:
    src: core-site.xml
    dest: /usr/local/hadoop-2.9.2/etc/hadoop/core-site.xml
  tags: hadoop

- name: ensure {{ hdfs_data_root_path }} exists
  file:
    path: "{{ item }}"
    state: directory
    owner: hadoop
  with_items: "{{ hdfs_data_root_path.split(',') }}"
  tags: hadoop

- name: configure hadoop hdfs-site.xml
  template:
    src: hdfs-site.xml
    dest: /usr/local/hadoop-2.9.2/etc/hadoop/hdfs-site.xml
  tags: hadoop

- name: configure hadoop mapred-site.xml
  copy:
    src: mapred-site.xml
    dest: /usr/local/hadoop-2.9.2/etc/hadoop/mapred-site.xml
  tags: hadoop

- name: configure hadoop yarn-site.xml
  template:
    src: yarn-site.xml
    dest: /usr/local/hadoop-2.9.2/etc/hadoop/yarn-site.xml
  tags: hadoop

- name: configure spark-defaults.conf
  copy:
    src: spark-defaults.conf
    dest: /usr/local/spark-2.4.0-bin-hadoop2.7/conf/spark-defaults.conf
  tags: spark

- name: configure spark-env.sh
  copy:
    src: spark-env.sh
    dest: /usr/local/spark-2.4.0-bin-hadoop2.7/conf/spark-env.sh
  tags: spark

- name: configure hadoop slaves list
  template:
    src: slaves.j2
    dest: /usr/local/hadoop-2.9.2/etc/hadoop/slaves
  tags: hadoop

- block:
    - name: format hdfs namenode
      shell: /usr/local/hadoop-2.9.2/bin/hdfs namenode -format -nonInteractive
      args:
        creates: '{{ item }}/nameNode/current/VERSION'
      with_items: "{{ hdfs_data_root_path.split(',') }}"
      tags: hadoop

    - name: assert dfs is running
      shell: jps
      register: assert_jps_namenode_running
      changed_when: no
      failed_when: "'NameNode' not in assert_jps_namenode_running.stdout"
      ignore_errors: yes
      tags: hadoop

    - name: start dfs if not already running (ui ports 50070 & 50075)
      shell: /usr/local/hadoop-2.9.2/sbin/start-dfs.sh
      when: assert_jps_namenode_running is failed
      tags: hadoop

    - name: assert dfs /user/hadoop dir exists
      shell: /usr/local/hadoop-2.9.2/bin/hdfs dfs -ls /user/hadoop
      register: assert_user_hadoop_dir_exists
      changed_when: no
      ignore_errors: yes
      tags: hadoop

    - name: create dfs /user/hadoop dir
      shell: /usr/local/hadoop-2.9.2/bin/hdfs dfs -mkdir -p /user/hadoop
      when: assert_user_hadoop_dir_exists is failed
      tags: hadoop

    - name: assert dfs /spark-logs dir exists
      shell: /usr/local/hadoop-2.9.2/bin/hdfs dfs -ls /spark-logs
      register: assert_spark_logs_dir_exists
      changed_when: no
      ignore_errors: yes
      tags: spark

    - name: create dfs /spark-logs dir
      shell: /usr/local/hadoop-2.9.2/bin/hdfs dfs -mkdir /spark-logs
      when: assert_spark_logs_dir_exists is failed
      tags: spark

    - name: assert yarn is running
      shell: jps
      register: assert_jps_resourcemanager_running
      changed_when: no
      failed_when: "'ResourceManager' not in assert_jps_resourcemanager_running.stdout"
      ignore_errors: yes
      tags: hadoop

    - name: start yarn if not already running (ui ports 8088 and 8042)
      shell: /usr/local/hadoop-2.9.2/sbin/start-yarn.sh
      when: assert_jps_resourcemanager_running is failed
      tags: hadoop

    - name: assert spark history server is running
      shell: jps
      register: assert_jps_spark_history_server_running
      changed_when: no
      failed_when: "'HistoryServer' not in assert_jps_spark_history_server_running.stdout"
      ignore_errors: yes
      tags: spark

    - name: start spark history server if not already running (ui port 18080)
      shell: /usr/local/spark-2.4.0-bin-hadoop2.7/sbin/start-history-server.sh
      when: assert_jps_spark_history_server_running is failed
      tags: spark

  when: "'master-nodes' in group_names"

...
