---

- name: ensure airflow user exists
  user:
    name: airflow
    comment: "Airflow user"
    shell: /bin/bash
  tags: airflow

- name: ensure airflow user has authorized_keys set
  authorized_key: user=airflow key="{{ lookup('file', 'public_keys/' + item + '_id_rsa.pub') }}"
  with_items: "{{ ['hadoop'] + airflow_admins }}"
  tags: airflow

- name: assert hdfs /user/airflow dir exists
  shell: /usr/local/hadoop-2.9.2/bin/hdfs dfs -ls /user/airflow
  register: assert_user_airflow_dir_exists
  changed_when: no
  ignore_errors: yes
  tags: airflow

- name: create hdfs /user/airflow dir if it doesn't exist
  shell: /usr/local/hadoop-2.9.2/bin/hdfs dfs -mkdir -p /user/airflow &&
         /usr/local/hadoop-2.9.2/bin/hdfs dfs -chown airflow:supergroup /user/airflow
  when: assert_user_airflow_dir_exists is failed
  become: yes
  become_user: hadoop
  tags: airflow

- name: ensure better bash history for airflow user
  blockinfile:
    dest: /home/airflow/.bashrc
    mode: 0644
    marker: "# {mark} ANSIBLE MANAGED BLOCK airflow-history"
    block: |
      HISTFILESIZE=20000
      HISTSIZE=10000
      HISTTIMEFORMAT='%y-%m-%dT%T  '
  become: yes
  become_user: airflow
  tags: airflow

- name: ensure airflow ~/airflow_home and ~/o3 dirs exists
  file:
    path: /home/airflow/{{ item }}
    state: directory
  with_items:
    - airflow_home
    - o3
  become: yes
  become_user: airflow
  tags: airflow

- name: ensure airflow config matches template
  template:
    src: airflow.cfg.j2
    dest: /home/airflow/airflow_home/airflow.cfg
  become: yes
  become_user: airflow
  notify:
    - airflow initdb
    - restart airflow-webserver
    - restart airflow-scheduler
  tags: airflow

- name: ensure latest code base is copied to remote server
  copy:
    src: '{{ item }}'
    dest: /home/airflow/o3/{{ item }}
  become: yes
  become_user: airflow
  with_items:
    - setup.py
    - o3/
    - environment-linux.yml
  tags: airflow

- name: ensure bzip2 is installed (required by anaconda on AWS CentOS)
  package:
    name: bzip2
    state: present
  tags: airflow

- name: ensure anacoda3 installer is present on target system
  copy:
    src: resources/Anaconda3-2018.12-Linux-x86_64.sh
    dest: /tmp/Anaconda3-2018.12-Linux-x86_64.sh
    owner: airflow
    mode: u=rwx,g=rwx,o=rx
  tags: airflow

- name: ensure anaconda3 shell setup is absent
  blockinfile:
    dest: /home/airflow/.bashrc
    marker: "# {mark} ANSIBLE MANAGED BLOCK airflow-anaconda3"
    block: |
      . /home/airflow/anaconda3/etc/profile.d/conda.sh
    state: absent
  become: yes
  become_user: airflow
  tags: airflow

- name: ensure anacoda3 is installed
  shell: /tmp/Anaconda3-2018.12-Linux-x86_64.sh -b
  args:
    creates: /home/airflow/anaconda3
  become: yes
  become_user: airflow
  register: anaconda3_installed
  tags: airflow

- name: ensure ~/.conda/pkgs dir is present
  file:
    path: /home/airflow/{{ item }}
    state: directory
  become: yes
  become_user: airflow
  with_items:
    - .conda
    - .conda/pkgs
  register: dot_conda_dirs
  tags: airflow

- name: ensure environment files to mitigate conda bugs exists
  file:
    path: /home/airflow/{{ item }}
    state: touch
    mode: 0664
  become: yes
  become_user: airflow
  with_items:
    - .conda/environments.txt
    - anaconda3/envs/.conda_envs_dir_test
  when: dot_conda_dirs is changed
  tags: airflow

- name: ensure conda is up-to-date
  shell: /home/airflow/anaconda3/bin/conda update -y conda
  become: yes
  become_user: airflow
  when: anaconda3_installed is changed
  tags: airflow

- name: ensure conda initializes bash
  shell: /home/airflow/anaconda3/bin/conda init bash
  become: yes
  become_user: airflow
  when: anaconda3_installed is changed
  tags: airflow

- name: ensure conda base env is deactivated in {{ bash_profile_file }}
  blockinfile:
    path: /home/airflow/{{ bash_profile_file }}
    marker: "# {mark} ANSIBLE MANAGED BLOCK airflow-conda"
    block: |
      conda deactivate
  become: yes
  become_user: airflow
  tags: airflow

- name: ensure conda environment is created based on environment-linux.yml
  shell: bash -il -c 'source /home/airflow/anaconda3/bin/activate && conda env
         create --name o3 python=3.6 -f /home/airflow/o3/environment-linux.yml'
  args:
    creates: /home/airflow/anaconda3/envs/o3
  become: yes
  become_user: airflow
  tags: airflow

- name: ensure o3 package is installed within the o3 conda environment
  shell: bash -il -c 'source /home/airflow/anaconda3/bin/activate o3 &&
         pip install -e /home/airflow/o3'
  become: yes
  become_user: airflow
  register: o3_package_installed
  changed_when: "'Found existing installation: o3' not in o3_package_installed.stdout"
  notify:
    - airflow initdb
    - restart airflow-webserver
    - restart airflow-scheduler
  tags: airflow

- name: ensure airflow-enviroment matches template
  template:
    src: environment.j2
    dest: /home/airflow/airflow-environment
  become: yes
  become_user: airflow
  notify:
    - restart airflow-webserver
    - restart airflow-scheduler
  tags: airflow

- name: ensure airflow-environment is sourced in {{ bash_profile_file }}
  blockinfile:
    path: /home/airflow/{{ bash_profile_file }}
    marker: "# {mark} ANSIBLE MANAGED BLOCK airflow-environment"
    block: |
      set -a
      source /home/airflow/airflow-environment
      export PATH=/usr/local/hadoop-2.9.2/bin:/usr/local/hadoop-2.9.2/sbin:$PATH
      export JAVA_HOME={{ java_home }}
  become: yes
  become_user: airflow
  tags: airflow

- name: ensure postgres database is started
  docker_container:
    name: airflow_postgres
    image: postgres:9.6
    state: started
    restart_policy: unless-stopped
    volume_driver: local
    volumes:
      - airflow_postgres:/var/lib/postgresql/data
    ports:
      - 5432:5432
    env:
      POSTGRES_DB: airflow
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: "{{ airflow_db_user_password }}"
  tags: airflow

- name: ensure airflow services matches template
  template:
    src: airflow-{{ item }}.service.j2
    dest: /etc/systemd/system/airflow-{{ item }}.service
  with_items:
    - webserver
    - scheduler
  register: add_airflow_services
  notify:
    - restart airflow-webserver
    - restart airflow-scheduler
  tags: airflow

- name: ensure daemon-reload is run on airflow service modification
  shell: systemctl daemon-reload
  when: add_airflow_services is changed
  tags: airflow

- name: ensure airflow services is running and auto-starting
  service:
    name: airflow-{{ item }}
    state: started
    enabled: yes
  with_items:
    - webserver
    - scheduler
  tags: airflow

...
